{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51e07c2f",
   "metadata": {},
   "source": [
    "### NLP100knock 40~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8acd65",
   "metadata": {},
   "source": [
    "#### 40. Zero-Shot推論\n",
    "\n",
    "以下の問題の解答を作成せよ。ただし、解答生成はzero-shot推論とせよ。\n",
    "\n",
    "- 9世紀に活躍した人物に関係するできごとについて述べた次のア～ウを年代の古い順に正しく並べよ。\n",
    "    - ア　藤原時平は，策謀を用いて菅原道真を政界から追放した。\n",
    "    - イ　嵯峨天皇は，藤原冬嗣らを蔵人頭に任命した。\n",
    "    - ウ　藤原良房は，承和の変後，藤原氏の中での北家の優位を確立した。\n",
    "    - 出典: 令和5年度第1回高等学校卒業程度認定試験問題 日本史AB 問題 日本史B 1 問3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aabd7e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`rope_scaling`'s original_max_position_embeddings field must be less than max_position_embeddings, got 8192 and max_position_embeddings=8192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 04-17 07:46:29 [config.py:2836] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 04-17 07:46:29 [config.py:689] This model supports multiple tasks: {'generate', 'score', 'reward', 'embed', 'classify'}. Defaulting to 'generate'.\n",
      "INFO 04-17 07:46:29 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3', speculative_config=None, tokenizer='tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False, \n",
      "INFO 04-17 07:46:31 [cuda.py:240] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
      "INFO 04-17 07:46:31 [cuda.py:289] Using XFormers backend.\n",
      "INFO 04-17 07:46:32 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 04-17 07:46:32 [model_runner.py:1110] Starting to load model tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3...\n",
      "INFO 04-17 07:46:33 [weight_utils.py:265] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:33<01:41, 33.95s/it]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:36<00:30, 15.49s/it]\n",
      "Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:39<00:09,  9.67s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:40<00:00,  6.19s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:40<00:00, 10.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-17 07:47:13 [loader.py:458] Loading weights took 40.20 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-17 07:47:14 [model_runner.py:1146] Model loading took 14.9596 GiB and 41.626356 seconds\n",
      "INFO 04-17 07:47:21 [worker.py:267] Memory profiling takes 7.20 seconds\n",
      "INFO 04-17 07:47:21 [worker.py:267] the current vLLM instance can use total_gpu_memory (23.64GiB) x gpu_memory_utilization (0.90) = 21.28GiB\n",
      "INFO 04-17 07:47:21 [worker.py:267] model weights take 14.96GiB; non_torch_memory takes 0.19GiB; PyTorch activation peak memory takes 1.23GiB; the rest of the memory reserved for KV Cache is 4.90GiB.\n",
      "INFO 04-17 07:47:22 [executor_base.py:112] # cuda blocks: 2506, # CPU blocks: 2048\n",
      "INFO 04-17 07:47:22 [executor_base.py:117] Maximum concurrency for 8192 tokens per request: 4.89x\n",
      "INFO 04-17 07:47:24 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:31<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-17 07:47:55 [model_runner.py:1598] Graph capturing finished in 31 secs, took 0.88 GiB\n",
      "INFO 04-17 07:47:55 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 40.94 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed prompts: 100%|██████████| 1/1 [00:06<00:00,  6.48s/it, est. speed input: 23.62 toks/s, output: 25.16 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正しい年代順は次のとおりです。\n",
      "\n",
      "**イ → ウ → ア**\n",
      "\n",
      "* **イ：**  嵯峨天皇は、809年に藤原冬嗣らを蔵人頭に任命しました。これは、藤原氏の台頭を象徴する出来事です。\n",
      "* **ウ：**  842年に起こった承和の変で、藤原良房は、他の藤原氏と対立し、勝利することで北家の優位を確立しました。\n",
      "* **ア：**  901年に、藤原時平は策謀を用いて菅原道真を政界から追放しました。これは、藤原氏の権力闘争の一環でした。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "model_name = \"tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "llm = LLM(\n",
    "    model=model_name,\n",
    "    tensor_parallel_size=1,\n",
    "    dtype=\"float16\",\n",
    ")\n",
    "\n",
    "sampling_params = SamplingParams(\n",
    "    temperature=0.6, top_p=0.9, max_tokens=512, stop=\"<|eot_id|>\"\n",
    ")\n",
    "\n",
    "\n",
    "message = [\n",
    "    {\"role\": \"system\", \"content\": \"あなたは誠実で優秀な日本人のアシスタントです。\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\":\n",
    "            \"\"\"\n",
    "            9世紀に活躍した人物に関係するできごとについて述べた次のア～ウを年代の古い順に正しく並べよ。\n",
    "            ア　藤原時平は，策謀を用いて菅原道真を政界から追放した。\n",
    "            イ　嵯峨天皇は，藤原冬嗣らを蔵人頭に任命した。\n",
    "            ウ　藤原良房は，承和の変後，藤原氏の中での北家の優位を確立した。\n",
    "            \"\"\"\n",
    "    },\n",
    "]\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    message, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "output = llm.generate(prompt, sampling_params)\n",
    "\n",
    "print(output[0].outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d12a730",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "正しい年代順は次のとおりです。\n",
    "\n",
    "**イ → ウ → ア**\n",
    "\n",
    "* **イ：**  嵯峨天皇は、809年に藤原冬嗣らを蔵人頭に任命しました。これは、藤原氏の台頭を象徴する出来事です。\n",
    "* **ウ：**  842年に起こった承和の変で、藤原良房は、他の藤原氏と対立し、勝利することで北家の優位を確立しました。\n",
    "* **ア：**  901年に、藤原時平は策謀を用いて菅原道真を政界から追放しました。これは、藤原氏の権力闘争の一環でした。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a09f433",
   "metadata": {},
   "source": [
    "### 41. Few-Shot推論\n",
    "\n",
    "以下の問題と解答を与え、問題40で示した質問の解答をfew-shot推論（この場合は4-shot推論）で生成せよ。\n",
    "\n",
    "- 日本の近代化に関連するできごとについて述べた次のア～ウを年代の古い順に正しく並べよ。\n",
    "    - ア　府知事・県令からなる地方官会議が設置された。\n",
    "    - イ　廃藩置県が実施され，中央から府知事・県令が派遣される体制になった。\n",
    "    - ウ　すべての藩主が，天皇に領地と領民を返還した。\n",
    "    - 解答: ウ→イ→ア\n",
    "    - 出典: 令和5年度第1回高等学校卒業程度認定試験問題 日本史AB 問題 日本史A 1 問8\n",
    "\n",
    "- 江戸幕府の北方での対外的な緊張について述べた次の文ア～ウを年代の古い順に正しく並べよ。\n",
    "    - ア　レザノフが長崎に来航したが，幕府が冷淡な対応をしたため，ロシア船が樺太や択捉島を攻撃した。\n",
    "    - イ　ゴローウニンが国後島に上陸し，幕府の役人に捕らえられ抑留された。\n",
    "    - ウ　ラクスマンが根室に来航し，漂流民を届けるとともに通商を求めた。\n",
    "    - 解答: ウ→ア→イ\n",
    "    - 出典: 令和5年度第1回高等学校卒業程度認定試験問題 日本史AB 問題 日本史B 3 問3\n",
    "\n",
    "- 中居屋重兵衛の生涯の期間におこったできごとについて述べた次のア～ウを，年代の古い順に正しく並べよ。\n",
    "    - ア　アヘン戦争がおこり，清がイギリスに敗北した。\n",
    "    - イ　異国船打払令が出され，外国船を撃退することが命じられた。\n",
    "    - ウ　桜田門外の変がおこり，大老の井伊直弼が暗殺された。\n",
    "    - 解答: イ→ア→ウ\n",
    "    - 出典: 令和4年度第1回高等学校卒業程度認定試験問題 日本史 問題 日本史A 1 問1\n",
    "\n",
    "- 加藤高明が外務大臣として提言を行ってから、内閣総理大臣となり演説を行うまでの時期のできごとについて述べた次のア～ウを，年代の古い順に正しく並べよ。\n",
    "    - ア　朝鮮半島において，独立を求める大衆運動である三・一独立運動が展開された。\n",
    "    - イ　関東大震災後の混乱のなかで，朝鮮人や中国人に対する殺傷事件がおきた。\n",
    "    - ウ　日本政府が，袁世凱政府に対して二十一カ条の要求を突き付けた。\n",
    "    - 解答: ウ→ア→イ\n",
    "    - 出典: 令和4年度第1回高等学校卒業程度認定試験問題 日本史 問題 日本史A 2 問4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e4ec1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.84it/s, est. speed input: 1315.40 toks/s, output: 11.05 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "イ→ウ→ア\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "model_name = \"tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "llm = LLM(\n",
    "    model=model_name,\n",
    "    tensor_parallel_size=1,\n",
    "    dtype=\"float16\",\n",
    ")\n",
    "\n",
    "sampling_params = SamplingParams(\n",
    "    temperature=0.6, top_p=0.9, max_tokens=512, stop=\"<|eot_id|>\"\n",
    ")\n",
    "\n",
    "message = [\n",
    "    {\"role\": \"system\", \"content\": \"あなたは誠実で優秀な日本人のアシスタントです。\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\":\n",
    "            \"\"\"\n",
    "            日本の近代化に関連するできごとについて述べた次のア～ウを年代の古い順に正しく並べよ。\n",
    "            ア　府知事・県令からなる地方官会議が設置された。\n",
    "            イ　廃藩置県が実施され，中央から府知事・県令が派遣される体制になった。\n",
    "            ウ　すべての藩主が，天皇に領地と領民を返還した。\n",
    "            \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"\"\"ウ→イ→ア\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\":\n",
    "            \"\"\"\n",
    "            江戸幕府の北方での対外的な緊張について述べた次の文ア～ウを年代の古い順に正しく並べよ。\n",
    "            ア　レザノフが長崎に来航したが，幕府が冷淡な対応をしたため，ロシア船が樺太や択捉島を攻撃した。\n",
    "            イ　ゴローウニンが国後島に上陸し，幕府の役人に捕らえられ抑留された。\n",
    "            ウ　ラクスマンが根室に来航し，漂流民を届けるとともに通商を求めた。\n",
    "            \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"\"\"ウ→ア→イ\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\":\n",
    "            \"\"\"\n",
    "            中居屋重兵衛の生涯の期間におこったできごとについて述べた次のア～ウを，年代の古い順に正しく並べよ。\n",
    "            ア　アヘン戦争がおこり，清がイギリスに敗北した。\n",
    "            イ　異国船打払令が出され，外国船を撃退することが命じられた。\n",
    "            ウ　桜田門外の変がおこり，大老の井伊直弼が暗殺された。\n",
    "            \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"\"\"イ→ア→ウ\"\"\"\n",
    "    },\n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"content\":\n",
    "            \"\"\"\n",
    "            加藤高明が外務大臣として提言を行ってから、内閣総理大臣となり演説を行うまでの時期のできごとについて述べた次のア～ウを，年代の古い順に正しく並べよ。\n",
    "            ア　朝鮮半島において，独立を求める大衆運動である三・一独立運動が展開された。\n",
    "            イ　関東大震災後の混乱のなかで，朝鮮人や中国人に対する殺傷事件がおきた。\n",
    "            ウ　日本政府が，袁世凱政府に対して二十一カ条の要求を突き付けた。\n",
    "            \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"\"\"ウ→ア→イ\"\"\"\n",
    "    },\n",
    "            {\n",
    "        \"role\": \"user\",\n",
    "        \"content\":\n",
    "            \"\"\"\n",
    "            9世紀に活躍した人物に関係するできごとについて述べた次のア～ウを年代の古い順に正しく並べよ。\n",
    "            ア　藤原時平は，策謀を用いて菅原道真を政界から追放した。\n",
    "            イ　嵯峨天皇は，藤原冬嗣らを蔵人頭に任命した。\n",
    "            ウ　藤原良房は，承和の変後，藤原氏の中での北家の優位を確立した。\n",
    "            \"\"\"\n",
    "    },    \n",
    "]\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    message, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "output = llm.generate(prompt, sampling_params)\n",
    "\n",
    "print(output[0].outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0510555",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "イ→ウ→ア\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40d1e87",
   "metadata": {},
   "source": [
    "### 42. 多肢選択問題の正解率\n",
    "\n",
    "JMMLU のいずれかの科目を大規模言語モデルに解答させ、その正解率を求めよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f8bc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/nlp-waseda/JMMLU.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85fffbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, est. speed input: 612.38 toks/s, output: 11.23 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.89it/s, est. speed input: 314.22 toks/s, output: 23.27 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.78s/it, est. speed input: 69.69 toks/s, output: 26.41 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s, est. speed input: 724.00 toks/s, output: 13.66 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.63it/s, est. speed input: 282.92 toks/s, output: 23.80 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.64it/s, est. speed input: 332.01 toks/s, output: 23.90 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.50s/it, est. speed input: 68.02 toks/s, output: 26.01 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s, est. speed input: 865.00 toks/s, output: 13.84 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.78it/s, est. speed input: 878.14 toks/s, output: 13.83 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.58it/s, est. speed input: 405.12 toks/s, output: 21.70 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s, est. speed input: 689.25 toks/s, output: 13.92 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it, est. speed input: 69.67 toks/s, output: 25.90 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s, est. speed input: 714.43 toks/s, output: 13.87 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s, est. speed input: 726.28 toks/s, output: 13.83 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.59it/s, est. speed input: 333.19 toks/s, output: 21.73 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.29s/it, est. speed input: 54.13 toks/s, output: 25.32 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:06<00:00,  6.21s/it, est. speed input: 23.86 toks/s, output: 25.47 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.55s/it, est. speed input: 56.85 toks/s, output: 24.31 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.80s/it, est. speed input: 48.92 toks/s, output: 23.57 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s, est. speed input: 181.37 toks/s, output: 25.42 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.99it/s, est. speed input: 489.50 toks/s, output: 20.22 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.80it/s, est. speed input: 359.40 toks/s, output: 22.64 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, est. speed input: 399.40 toks/s, output: 22.36 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.93it/s, est. speed input: 243.02 toks/s, output: 23.33 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:04<00:00,  4.17s/it, est. speed input: 36.70 toks/s, output: 24.46 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.72it/s, est. speed input: 738.14 toks/s, output: 13.67 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.70s/it, est. speed input: 34.33 toks/s, output: 24.33 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.61it/s, est. speed input: 255.68 toks/s, output: 23.72 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s, est. speed input: 671.29 toks/s, output: 13.70 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.18it/s, est. speed input: 336.82 toks/s, output: 22.45 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s, est. speed input: 823.90 toks/s, output: 13.62 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.80s/it, est. speed input: 65.28 toks/s, output: 23.99 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.05s/it, est. speed input: 36.10 toks/s, output: 21.00 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, est. speed input: 337.61 toks/s, output: 22.29 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.92it/s, est. speed input: 261.50 toks/s, output: 21.31 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.36s/it, est. speed input: 54.67 toks/s, output: 22.88 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.16s/it, est. speed input: 37.37 toks/s, output: 23.75 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s, est. speed input: 794.62 toks/s, output: 13.58 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:05<00:00,  5.87s/it, est. speed input: 21.82 toks/s, output: 10.74 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s, est. speed input: 643.06 toks/s, output: 12.99 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, est. speed input: 367.21 toks/s, output: 22.35 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.57s/it, est. speed input: 30.02 toks/s, output: 10.94 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:05<00:00,  5.15s/it, est. speed input: 22.91 toks/s, output: 11.26 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.27it/s, est. speed input: 777.74 toks/s, output: 12.75 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s, est. speed input: 832.82 toks/s, output: 13.54 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.16it/s, est. speed input: 243.78 toks/s, output: 23.94 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s, est. speed input: 772.02 toks/s, output: 13.42 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s, est. speed input: 785.40 toks/s, output: 13.54 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.64it/s, est. speed input: 835.26 toks/s, output: 13.58 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, est. speed input: 694.01 toks/s, output: 13.61 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s, est. speed input: 711.01 toks/s, output: 13.80 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.97s/it, est. speed input: 55.92 toks/s, output: 22.37 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.99it/s, est. speed input: 393.35 toks/s, output: 20.07 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.51it/s, est. speed input: 347.43 toks/s, output: 21.27 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:06<00:00,  6.18s/it, est. speed input: 20.73 toks/s, output: 9.39 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.34it/s, est. speed input: 366.81 toks/s, output: 20.19 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, est. speed input: 333.14 toks/s, output: 21.59 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, est. speed input: 383.09 toks/s, output: 22.16 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s, est. speed input: 646.64 toks/s, output: 13.47 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s, est. speed input: 864.73 toks/s, output: 13.51 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.36s/it, est. speed input: 54.72 toks/s, output: 22.48 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  5.82it/s, est. speed input: 821.15 toks/s, output: 11.81 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, est. speed input: 812.95 toks/s, output: 13.43 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:05<00:00,  5.10s/it, est. speed input: 25.09 toks/s, output: 10.59 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.32it/s, est. speed input: 754.05 toks/s, output: 12.78 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, est. speed input: 613.98 toks/s, output: 13.49 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.53it/s, est. speed input: 327.15 toks/s, output: 21.33 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:06<00:00,  6.88s/it, est. speed input: 21.95 toks/s, output: 9.30 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, est. speed input: 300.30 toks/s, output: 21.45 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s, est. speed input: 778.19 toks/s, output: 13.53 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:06<00:00,  6.04s/it, est. speed input: 29.50 toks/s, output: 9.45 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s, est. speed input: 767.91 toks/s, output: 12.80 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.48it/s, est. speed input: 404.66 toks/s, output: 21.11 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, est. speed input: 704.57 toks/s, output: 13.42 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:05<00:00,  5.13s/it, est. speed input: 22.62 toks/s, output: 9.75 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:04<00:00,  4.64s/it, est. speed input: 25.48 toks/s, output: 11.23 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.32it/s, est. speed input: 588.10 toks/s, output: 12.92 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:07<00:00,  7.10s/it, est. speed input: 19.16 toks/s, output: 9.86 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:07<00:00,  7.49s/it, est. speed input: 19.64 toks/s, output: 9.89 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  5.87it/s, est. speed input: 694.10 toks/s, output: 11.86 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:05<00:00,  5.93s/it, est. speed input: 22.96 toks/s, output: 9.96 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:05<00:00,  5.49s/it, est. speed input: 22.59 toks/s, output: 10.39 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.16it/s, est. speed input: 243.57 toks/s, output: 19.57 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s, est. speed input: 677.08 toks/s, output: 13.27 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, est. speed input: 762.92 toks/s, output: 13.38 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.41it/s, est. speed input: 404.86 toks/s, output: 20.76 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.52it/s, est. speed input: 289.02 toks/s, output: 20.28 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, est. speed input: 300.01 toks/s, output: 18.56 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.66it/s, est. speed input: 304.53 toks/s, output: 21.37 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:06<00:00,  6.45s/it, est. speed input: 20.33 toks/s, output: 8.53 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s, est. speed input: 613.78 toks/s, output: 12.92 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.45it/s, est. speed input: 375.96 toks/s, output: 20.88 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.67it/s, est. speed input: 334.43 toks/s, output: 21.57 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s, est. speed input: 156.59 toks/s, output: 11.84 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.73it/s, est. speed input: 400.08 toks/s, output: 18.87 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.67s/it, est. speed input: 22.95 toks/s, output: 9.11 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.61it/s, est. speed input: 293.94 toks/s, output: 18.37 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s, est. speed input: 832.35 toks/s, output: 13.11 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.47it/s, est. speed input: 304.43 toks/s, output: 20.99 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.50s/it, est. speed input: 34.48 toks/s, output: 10.83 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, est. speed input: 263.25 toks/s, output: 18.15 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s, est. speed input: 294.64 toks/s, output: 21.04 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s, est. speed input: 781.19 toks/s, output: 13.13 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s, est. speed input: 616.93 toks/s, output: 13.41 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.07it/s, est. speed input: 220.88 toks/s, output: 18.75 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.33it/s, est. speed input: 282.00 toks/s, output: 18.80 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s, est. speed input: 657.09 toks/s, output: 13.27 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, est. speed input: 362.93 toks/s, output: 20.82 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:05<00:00,  5.52s/it, est. speed input: 19.75 toks/s, output: 9.24 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.45it/s, est. speed input: 349.98 toks/s, output: 17.37 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.92it/s, est. speed input: 374.53 toks/s, output: 20.64 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.73it/s, est. speed input: 204.20 toks/s, output: 19.20 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:07<00:00,  7.90s/it, est. speed input: 19.88 toks/s, output: 8.74 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.43it/s, est. speed input: 382.30 toks/s, output: 17.38 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.80s/it, est. speed input: 29.25 toks/s, output: 10.28 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.79s/it, est. speed input: 29.59 toks/s, output: 11.09 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  5.76it/s, est. speed input: 688.54 toks/s, output: 11.67 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.59it/s, est. speed input: 256.92 toks/s, output: 20.97 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s, est. speed input: 708.38 toks/s, output: 14.17 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s, est. speed input: 877.19 toks/s, output: 14.26 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, est. speed input: 180.43 toks/s, output: 11.69 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.33s/it, est. speed input: 33.31 toks/s, output: 11.40 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.04it/s, est. speed input: 237.55 toks/s, output: 18.43 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.75it/s, est. speed input: 304.08 toks/s, output: 19.35 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, est. speed input: 611.74 toks/s, output: 10.19 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.85it/s, est. speed input: 335.65 toks/s, output: 17.21 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.75it/s, est. speed input: 334.05 toks/s, output: 19.32 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.74it/s, est. speed input: 713.05 toks/s, output: 13.71 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.90it/s, est. speed input: 723.58 toks/s, output: 14.05 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.79it/s, est. speed input: 171.04 toks/s, output: 12.60 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.24s/it, est. speed input: 13.72 toks/s, output: 9.59 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:07<00:00,  7.10s/it, est. speed input: 16.92 toks/s, output: 9.73 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:06<00:00,  6.36s/it, est. speed input: 19.50 toks/s, output: 9.91 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.04it/s, est. speed input: 257.77 toks/s, output: 18.41 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.29s/it, est. speed input: 86.31 toks/s, output: 11.66 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.08it/s, est. speed input: 280.10 toks/s, output: 16.72 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, est. speed input: 341.69 toks/s, output: 18.47 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it, est. speed input: 133.70 toks/s, output: 7.92 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:04<00:00,  4.85s/it, est. speed input: 23.52 toks/s, output: 10.31 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:04<00:00,  4.81s/it, est. speed input: 23.95 toks/s, output: 10.41 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:05<00:00,  5.08s/it, est. speed input: 25.02 toks/s, output: 10.24 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.88it/s, est. speed input: 340.03 toks/s, output: 17.44 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, est. speed input: 742.85 toks/s, output: 13.26 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.82it/s, est. speed input: 337.63 toks/s, output: 19.86 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:05<00:00,  5.43s/it, est. speed input: 20.99 toks/s, output: 9.02 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:07<00:00,  7.30s/it, est. speed input: 17.95 toks/s, output: 9.59 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s, est. speed input: 533.80 toks/s, output: 12.27 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.35s/it, est. speed input: 19.46 toks/s, output: 9.09 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s, est. speed input: 639.37 toks/s, output: 11.95 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.67it/s, est. speed input: 290.19 toks/s, output: 18.81 toks/s]\n",
      "100%|██████████| 150/150 [04:08<00:00,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正解数: 70 / 150 = 46.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from vllm import LLM, SamplingParams\n",
    "from tqdm import tqdm\n",
    "\n",
    "# モデルとトークナイザの準備\n",
    "# model_name = \"tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# llm = LLM(\n",
    "#     model=model_name,\n",
    "#     tensor_parallel_size=1,\n",
    "#     dtype=\"float16\",\n",
    "# )\n",
    "\n",
    "sampling_params = SamplingParams(\n",
    "    temperature=0.6, top_p=0.9, max_tokens=512, stop=\"<|eot_id|>\"\n",
    ")\n",
    "\n",
    "df = pd.read_csv(\"JMMLU/JMMLU/japanese_history.csv\", header=None)\n",
    "df.columns = [\"問題\", \"選択肢A\", \"選択肢B\", \"選択肢C\", \"選択肢D\", \"正解\"]\n",
    "\n",
    "def create_prompt(question, a, b, c, d):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": \"あなたは誠実で優秀な日本人のアシスタントです。\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"{question}\\nA. {a}\\nB. {b}\\nC. {c}\\nD. {d}\\n正しい選択肢を一つだけアルファベットで答えてください。\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "correct = 0\n",
    "total = len(df)\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=total):\n",
    "    messages = create_prompt(row[\"問題\"], row[\"選択肢A\"], row[\"選択肢B\"], row[\"選択肢C\"], row[\"選択肢D\"])\n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "    output = llm.generate(prompt, sampling_params)\n",
    "    answer = output[0].outputs[0].text.strip()\n",
    "\n",
    "    if answer.upper().startswith(row[\"正解\"].strip().upper()):\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / total * 100\n",
    "print(f\"正解数: {correct} / {total} = {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cddf7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "正解数: 75 / 150 = 50.00%\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca20f4c",
   "metadata": {},
   "source": [
    "### 43. 応答のバイアス\n",
    "\n",
    "問題42において、実験設定を変化させると正解率が変化するかどうかを調べよ。実験設定の例としては、大規模言語モデルの温度パラメータ、プロンプト、多肢選択肢の順番、多肢選択肢の記号などが考えられる。\n",
    "\n",
    "正解の選択肢を全てDに入れ替えて解答させる例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1f1a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from vllm import LLM, SamplingParams\n",
    "from tqdm import tqdm\n",
    "\n",
    "# モデルとトークナイザの準備\n",
    "# model_name = \"tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# llm = LLM(\n",
    "#     model=model_name,\n",
    "#     tensor_parallel_size=1,\n",
    "#     dtype=\"float16\",\n",
    "# )\n",
    "\n",
    "df = pd.read_csv(\"JMMLU/JMMLU/japanese_history.csv\", header=None)\n",
    "df.columns = [\"問題\", \"選択肢A\", \"選択肢B\", \"選択肢C\", \"選択肢D\", \"正解\"]\n",
    "\n",
    "def create_prompt(question, a, b, c, d):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": \"あなたは誠実で優秀な日本人のアシスタントです。\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"{question}\\nA. {a}\\nB. {b}\\nC. {c}\\nD. {d}\\n正しい選択肢を一つだけアルファベットで答えてください。\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "def llm_score(sampling_params=sampling_params):\n",
    "    correct = 0\n",
    "    total = len(df)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        messages = create_prompt(row[\"問題\"], row[\"選択肢A\"], row[\"選択肢B\"], row[\"選択肢C\"], row[\"選択肢D\"])\n",
    "        prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "        output = llm.generate(prompt,sampling_params) \n",
    "        answer = output[0].outputs[0].text.strip()\n",
    "\n",
    "        if answer.upper().startswith(row[\"正解\"].strip().upper()):\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = correct / total * 100\n",
    "    print(f\"正解数: {correct} / {total} = {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a3d6e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temperature:  0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s, est. speed input: 528.55 toks/s, output: 9.70 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.74it/s, est. speed input: 297.64 toks/s, output: 22.05 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, est. speed input: 395.73 toks/s, output: 22.34 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s, est. speed input: 730.02 toks/s, output: 13.77 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.01s/it, est. speed input: 53.30 toks/s, output: 24.41 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.61it/s, est. speed input: 329.20 toks/s, output: 23.70 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.67s/it, est. speed input: 27.79 toks/s, output: 10.90 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s, est. speed input: 789.48 toks/s, output: 12.63 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s, est. speed input: 919.47 toks/s, output: 14.48 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.69it/s, est. speed input: 417.83 toks/s, output: 22.38 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s, est. speed input: 732.54 toks/s, output: 14.80 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.82s/it, est. speed input: 62.11 toks/s, output: 23.09 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  7.03it/s, est. speed input: 732.94 toks/s, output: 14.23 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.71it/s, est. speed input: 391.82 toks/s, output: 22.39 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.68it/s, est. speed input: 340.66 toks/s, output: 22.21 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, est. speed input: 910.57 toks/s, output: 14.68 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.77s/it, est. speed input: 16.88 toks/s, output: 8.67 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:05<00:00,  5.65s/it, est. speed input: 25.66 toks/s, output: 12.03 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:07<00:00,  7.07s/it, est. speed input: 19.37 toks/s, output: 9.19 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s, est. speed input: 146.31 toks/s, output: 21.88 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  4.12it/s, est. speed input: 501.42 toks/s, output: 20.72 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.33s/it, est. speed input: 54.46 toks/s, output: 22.30 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, est. speed input: 392.88 toks/s, output: 22.00 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.32it/s, est. speed input: 292.44 toks/s, output: 23.39 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.74s/it, est. speed input: 40.93 toks/s, output: 21.94 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s, est. speed input: 728.77 toks/s, output: 13.49 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:07<00:00,  7.94s/it, est. speed input: 16.01 toks/s, output: 9.83 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.42it/s, est. speed input: 236.55 toks/s, output: 21.95 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s, est. speed input: 654.36 toks/s, output: 13.35 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s, est. speed input: 704.57 toks/s, output: 13.42 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.39it/s, est. speed input: 290.89 toks/s, output: 21.64 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:04<00:00,  4.64s/it, est. speed input: 25.23 toks/s, output: 9.27 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.74s/it, est. speed input: 40.21 toks/s, output: 13.16 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.83it/s, est. speed input: 302.73 toks/s, output: 19.99 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:05<00:00,  5.16s/it, est. speed input: 26.21 toks/s, output: 9.71 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:05<00:00,  5.12s/it, est. speed input: 25.20 toks/s, output: 10.55 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:04<00:00,  4.56s/it, est. speed input: 25.88 toks/s, output: 10.96 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s, est. speed input: 733.10 toks/s, output: 12.53 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:05<00:00,  5.47s/it, est. speed input: 23.40 toks/s, output: 10.24 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s, est. speed input: 636.30 toks/s, output: 12.85 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, est. speed input: 351.87 toks/s, output: 21.42 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.93s/it, est. speed input: 27.25 toks/s, output: 10.19 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.36it/s, est. speed input: 279.55 toks/s, output: 18.95 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.65it/s, est. speed input: 325.96 toks/s, output: 21.37 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.68it/s, est. speed input: 332.32 toks/s, output: 18.91 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.05it/s, est. speed input: 231.24 toks/s, output: 20.64 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s, est. speed input: 772.23 toks/s, output: 13.43 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s, est. speed input: 785.84 toks/s, output: 13.55 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s, est. speed input: 833.48 toks/s, output: 13.55 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, est. speed input: 689.13 toks/s, output: 13.51 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s, est. speed input: 700.04 toks/s, output: 13.59 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  9.00s/it, est. speed input: 12.23 toks/s, output: 9.12 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.48it/s, est. speed input: 343.92 toks/s, output: 17.55 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.38it/s, est. speed input: 335.17 toks/s, output: 20.52 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s, est. speed input: 214.32 toks/s, output: 15.07 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s, est. speed input: 687.27 toks/s, output: 12.61 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s, est. speed input: 324.47 toks/s, output: 21.03 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.93it/s, est. speed input: 357.64 toks/s, output: 20.69 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.86it/s, est. speed input: 180.04 toks/s, output: 13.13 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.55it/s, est. speed input: 329.33 toks/s, output: 18.01 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:05<00:00,  5.83s/it, est. speed input: 22.15 toks/s, output: 9.27 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s, est. speed input: 706.06 toks/s, output: 10.16 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s, est. speed input: 803.15 toks/s, output: 13.27 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:05<00:00,  5.37s/it, est. speed input: 23.84 toks/s, output: 9.69 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s, est. speed input: 737.44 toks/s, output: 12.50 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.37it/s, est. speed input: 310.33 toks/s, output: 20.46 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.41it/s, est. speed input: 315.91 toks/s, output: 20.60 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:07<00:00,  7.39s/it, est. speed input: 20.44 toks/s, output: 8.53 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.65it/s, est. speed input: 261.26 toks/s, output: 18.66 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s, est. speed input: 764.87 toks/s, output: 13.30 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.40s/it, est. speed input: 21.21 toks/s, output: 8.70 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  5.98it/s, est. speed input: 731.26 toks/s, output: 12.19 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.35it/s, est. speed input: 388.04 toks/s, output: 20.24 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s, est. speed input: 699.84 toks/s, output: 13.33 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.79s/it, est. speed input: 13.21 toks/s, output: 8.77 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s, est. speed input: 676.25 toks/s, output: 11.46 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.85it/s, est. speed input: 261.45 toks/s, output: 20.11 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.29s/it, est. speed input: 16.40 toks/s, output: 8.68 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:07<00:00,  7.81s/it, est. speed input: 18.84 toks/s, output: 9.48 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.06it/s, est. speed input: 716.51 toks/s, output: 12.25 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:06<00:00,  6.35s/it, est. speed input: 21.43 toks/s, output: 9.45 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:05<00:00,  5.59s/it, est. speed input: 22.18 toks/s, output: 10.02 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  5.66it/s, est. speed input: 647.82 toks/s, output: 11.57 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s, est. speed input: 673.44 toks/s, output: 13.20 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, est. speed input: 764.99 toks/s, output: 13.42 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.26it/s, est. speed input: 383.92 toks/s, output: 19.69 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, est. speed input: 136.19 toks/s, output: 11.95 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  5.82it/s, est. speed input: 570.55 toks/s, output: 11.76 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.45it/s, est. speed input: 281.50 toks/s, output: 19.75 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:05<00:00,  5.86s/it, est. speed input: 22.38 toks/s, output: 8.71 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s, est. speed input: 588.91 toks/s, output: 12.40 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, est. speed input: 346.15 toks/s, output: 19.23 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.32it/s, est. speed input: 289.72 toks/s, output: 18.69 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s, est. speed input: 151.51 toks/s, output: 8.91 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.23it/s, est. speed input: 346.64 toks/s, output: 16.35 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.49s/it, est. speed input: 18.97 toks/s, output: 8.77 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.38it/s, est. speed input: 268.89 toks/s, output: 16.80 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s, est. speed input: 832.35 toks/s, output: 13.11 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.18s/it, est. speed input: 27.35 toks/s, output: 9.43 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.12s/it, est. speed input: 40.54 toks/s, output: 12.73 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.76it/s, est. speed input: 242.40 toks/s, output: 16.72 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s, est. speed input: 644.47 toks/s, output: 13.15 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s, est. speed input: 791.61 toks/s, output: 13.30 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s, est. speed input: 615.66 toks/s, output: 13.38 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.03it/s, est. speed input: 216.76 toks/s, output: 18.40 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s, est. speed input: 159.64 toks/s, output: 10.64 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, est. speed input: 580.85 toks/s, output: 11.73 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:07<00:00,  7.81s/it, est. speed input: 15.62 toks/s, output: 9.35 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:05<00:00,  5.02s/it, est. speed input: 21.72 toks/s, output: 10.16 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.24it/s, est. speed input: 318.11 toks/s, output: 15.79 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.59it/s, est. speed input: 331.83 toks/s, output: 18.29 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.20s/it, est. speed input: 97.73 toks/s, output: 9.19 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.43s/it, est. speed input: 18.62 toks/s, output: 9.25 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.09it/s, est. speed input: 343.62 toks/s, output: 15.62 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.14it/s, est. speed input: 239.16 toks/s, output: 19.39 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:06<00:00,  6.11s/it, est. speed input: 18.33 toks/s, output: 8.51 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s, est. speed input: 677.91 toks/s, output: 11.49 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.62it/s, est. speed input: 258.59 toks/s, output: 21.11 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.85it/s, est. speed input: 186.65 toks/s, output: 14.93 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.07it/s, est. speed input: 256.57 toks/s, output: 16.69 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.52it/s, est. speed input: 274.18 toks/s, output: 17.77 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.56it/s, est. speed input: 285.92 toks/s, output: 15.45 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s, est. speed input: 736.70 toks/s, output: 12.70 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.10it/s, est. speed input: 232.71 toks/s, output: 14.81 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.29it/s, est. speed input: 275.52 toks/s, output: 16.07 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.96it/s, est. speed input: 348.20 toks/s, output: 17.86 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s, est. speed input: 157.23 toks/s, output: 9.10 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.09it/s, est. speed input: 218.97 toks/s, output: 16.84 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s, est. speed input: 672.05 toks/s, output: 13.05 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.85it/s, est. speed input: 176.51 toks/s, output: 13.01 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.14s/it, est. speed input: 12.37 toks/s, output: 9.20 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:06<00:00,  6.39s/it, est. speed input: 18.78 toks/s, output: 9.55 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s, est. speed input: 156.07 toks/s, output: 17.62 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.03s/it, est. speed input: 122.30 toks/s, output: 8.74 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  5.74it/s, est. speed input: 645.96 toks/s, output: 11.64 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.99it/s, est. speed input: 267.78 toks/s, output: 15.99 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.87it/s, est. speed input: 209.48 toks/s, output: 11.32 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.94it/s, est. speed input: 263.83 toks/s, output: 15.63 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:05<00:00,  5.52s/it, est. speed input: 20.66 toks/s, output: 8.88 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.06it/s, est. speed input: 237.92 toks/s, output: 16.55 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.29it/s, est. speed input: 293.10 toks/s, output: 16.15 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.51it/s, est. speed input: 295.89 toks/s, output: 15.17 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s, est. speed input: 731.30 toks/s, output: 13.06 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.14it/s, est. speed input: 257.08 toks/s, output: 15.12 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:04<00:00,  4.95s/it, est. speed input: 23.06 toks/s, output: 9.91 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:05<00:00,  5.12s/it, est. speed input: 25.61 toks/s, output: 9.78 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  5.80it/s, est. speed input: 511.85 toks/s, output: 11.76 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.75s/it, est. speed input: 18.68 toks/s, output: 8.83 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, est. speed input: 635.70 toks/s, output: 11.88 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.51it/s, est. speed input: 273.30 toks/s, output: 17.71 toks/s]\n",
      "100%|██████████| 150/150 [04:35<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正解数: 75 / 150 = 50.00%\n",
      "temperature:  0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s, est. speed input: 710.03 toks/s, output: 13.03 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s, est. speed input: 135.56 toks/s, output: 10.04 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s, est. speed input: 276.24 toks/s, output: 15.59 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.32it/s, est. speed input: 683.47 toks/s, output: 12.89 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:05<00:00,  5.23s/it, est. speed input: 20.47 toks/s, output: 8.80 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.80it/s, est. speed input: 226.89 toks/s, output: 16.34 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:04<00:00,  4.36s/it, est. speed input: 23.40 toks/s, output: 8.95 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  5.34it/s, est. speed input: 678.80 toks/s, output: 10.86 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s, est. speed input: 821.42 toks/s, output: 12.93 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.96it/s, est. speed input: 335.00 toks/s, output: 17.94 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s, est. speed input: 651.06 toks/s, output: 13.15 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:04<00:00,  4.94s/it, est. speed input: 22.87 toks/s, output: 8.70 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s, est. speed input: 577.75 toks/s, output: 11.22 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.88it/s, est. speed input: 305.94 toks/s, output: 17.48 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.61it/s, est. speed input: 241.90 toks/s, output: 15.77 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.17s/it, est. speed input: 106.32 toks/s, output: 8.57 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:21<00:00, 21.07s/it, est. speed input: 7.02 toks/s, output: 8.59 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:07<00:00,  7.41s/it, est. speed input: 19.57 toks/s, output: 9.18 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:07<00:00,  7.05s/it, est. speed input: 19.44 toks/s, output: 9.23 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it, est. speed input: 65.12 toks/s, output: 9.13 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.53it/s, est. speed input: 309.57 toks/s, output: 12.79 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s, est. speed input: 168.90 toks/s, output: 10.64 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s, est. speed input: 199.73 toks/s, output: 11.18 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s, est. speed input: 144.60 toks/s, output: 11.57 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.35s/it, est. speed input: 16.37 toks/s, output: 8.56 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  5.21it/s, est. speed input: 572.98 toks/s, output: 10.61 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.00it/s, est. speed input: 771.34 toks/s, output: 12.15 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s, est. speed input: 146.77 toks/s, output: 13.62 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  5.36it/s, est. speed input: 530.06 toks/s, output: 10.82 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, est. speed input: 170.46 toks/s, output: 11.36 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, est. speed input: 641.41 toks/s, output: 10.60 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:04<00:00,  4.83s/it, est. speed input: 24.22 toks/s, output: 8.90 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:04<00:00,  4.21s/it, est. speed input: 26.12 toks/s, output: 8.55 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s, est. speed input: 147.63 toks/s, output: 9.75 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:06<00:00,  6.72s/it, est. speed input: 20.11 toks/s, output: 8.49 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:06<00:00,  6.69s/it, est. speed input: 19.29 toks/s, output: 8.53 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.16s/it, est. speed input: 14.47 toks/s, output: 8.46 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, est. speed input: 608.09 toks/s, output: 10.39 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:06<00:00,  6.66s/it, est. speed input: 19.23 toks/s, output: 8.56 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, est. speed input: 517.69 toks/s, output: 10.46 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s, est. speed input: 183.05 toks/s, output: 11.14 toks/s]\n",
      " 27%|██▋       | 41/150 [01:52<04:58,  2.73s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m sampling_params \u001b[38;5;241m=\u001b[39m SamplingParams(\n\u001b[1;32m      4\u001b[0m     temperature\u001b[38;5;241m=\u001b[39mtemp, top_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, stop\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<|eot_id|>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature: \u001b[39m\u001b[38;5;124m\"\u001b[39m, temp)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mllm_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampling_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 36\u001b[0m, in \u001b[0;36mllm_score\u001b[0;34m(sampling_params)\u001b[0m\n\u001b[1;32m     33\u001b[0m messages \u001b[38;5;241m=\u001b[39m create_prompt(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m問題\u001b[39m\u001b[38;5;124m\"\u001b[39m], row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m選択肢A\u001b[39m\u001b[38;5;124m\"\u001b[39m], row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m選択肢B\u001b[39m\u001b[38;5;124m\"\u001b[39m], row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m選択肢C\u001b[39m\u001b[38;5;124m\"\u001b[39m], row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m選択肢D\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     34\u001b[0m prompt \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(messages, tokenize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 36\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43msampling_params\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     37\u001b[0m answer \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39moutputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;241m.\u001b[39mstartswith(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m正解\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mupper()):\n",
      "File \u001b[0;32m~/miniconda3/envs/b3comp2/lib/python3.11/site-packages/vllm/utils.py:1134\u001b[0m, in \u001b[0;36mdeprecate_kwargs.<locals>.wrapper.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m             msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00madditional_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1129\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1130\u001b[0m             \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m(msg),\n\u001b[1;32m   1131\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# The inner function takes up one level\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m         )\n\u001b[0;32m-> 1134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/b3comp2/lib/python3.11/site-packages/vllm/entrypoints/llm.py:470\u001b[0m, in \u001b[0;36mLLM.generate\u001b[0;34m(self, prompts, sampling_params, prompt_token_ids, use_tqdm, lora_request, prompt_adapter_request, guided_options_request, priority)\u001b[0m\n\u001b[1;32m    460\u001b[0m     sampling_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_default_sampling_params()\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_and_add_requests(\n\u001b[1;32m    463\u001b[0m     prompts\u001b[38;5;241m=\u001b[39mparsed_prompts,\n\u001b[1;32m    464\u001b[0m     params\u001b[38;5;241m=\u001b[39msampling_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    467\u001b[0m     guided_options\u001b[38;5;241m=\u001b[39mguided_options_request,\n\u001b[1;32m    468\u001b[0m     priority\u001b[38;5;241m=\u001b[39mpriority)\n\u001b[0;32m--> 470\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_tqdm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_class\u001b[38;5;241m.\u001b[39mvalidate_outputs(outputs, RequestOutput)\n",
      "File \u001b[0;32m~/miniconda3/envs/b3comp2/lib/python3.11/site-packages/vllm/entrypoints/llm.py:1409\u001b[0m, in \u001b[0;36mLLM._run_engine\u001b[0;34m(self, use_tqdm)\u001b[0m\n\u001b[1;32m   1407\u001b[0m total_out_toks \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1408\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_engine\u001b[38;5;241m.\u001b[39mhas_unfinished_requests():\n\u001b[0;32m-> 1409\u001b[0m     step_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m step_outputs:\n\u001b[1;32m   1411\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output\u001b[38;5;241m.\u001b[39mfinished:\n",
      "File \u001b[0;32m~/miniconda3/envs/b3comp2/lib/python3.11/site-packages/vllm/engine/llm_engine.py:1431\u001b[0m, in \u001b[0;36mLLMEngine.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     execute_model_req\u001b[38;5;241m.\u001b[39masync_callback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_callbacks[\n\u001b[1;32m   1428\u001b[0m         virtual_engine]\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1431\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecute_model_req\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecute_model_req\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1433\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_skip_scheduling_next_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1434\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InputProcessingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1435\u001b[0m     \u001b[38;5;66;03m# The input for this request cannot be processed, so we must\u001b[39;00m\n\u001b[1;32m   1436\u001b[0m     \u001b[38;5;66;03m# abort it. If there are remaining requests in the batch that\u001b[39;00m\n\u001b[1;32m   1437\u001b[0m     \u001b[38;5;66;03m# have been scheduled, they will be retried on the next step.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/b3comp2/lib/python3.11/site-packages/vllm/executor/executor_base.py:140\u001b[0m, in \u001b[0;36mExecutorBase.execute_model\u001b[0;34m(self, execute_model_req)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute_model\u001b[39m(\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m, execute_model_req: ExecuteModelRequest\n\u001b[1;32m    139\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[List[Union[SamplerOutput, PoolerOutput]]]:\n\u001b[0;32m--> 140\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollective_rpc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexecute_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexecute_model_req\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/b3comp2/lib/python3.11/site-packages/vllm/executor/uniproc_executor.py:56\u001b[0m, in \u001b[0;36mUniProcExecutor.collective_rpc\u001b[0;34m(self, method, timeout, args, kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 56\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mrun_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdriver_worker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [answer]\n",
      "File \u001b[0;32m~/miniconda3/envs/b3comp2/lib/python3.11/site-packages/vllm/utils.py:2378\u001b[0m, in \u001b[0;36mrun_method\u001b[0;34m(obj, method, args, kwargs)\u001b[0m\n\u001b[1;32m   2376\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2377\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(method, obj)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 2378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/b3comp2/lib/python3.11/site-packages/vllm/worker/worker_base.py:420\u001b[0m, in \u001b[0;36mLocalOrDistributedWorkerBase.execute_model\u001b[0;34m(self, execute_model_req)\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservability_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    416\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservability_config\u001b[38;5;241m.\u001b[39mcollect_model_execute_time):\n\u001b[1;32m    417\u001b[0m         orig_model_execute_time \u001b[38;5;241m=\u001b[39m intermediate_tensors\u001b[38;5;241m.\u001b[39mtensors\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    418\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_execute_time\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m--> 420\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkv_caches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mworker_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvirtual_engine\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintermediate_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mintermediate_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m model_execute_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m get_pp_group()\u001b[38;5;241m.\u001b[39mis_last_rank:\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;66;03m# output is IntermediateTensors\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/b3comp2/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/b3comp2/lib/python3.11/site-packages/vllm/worker/model_runner.py:1826\u001b[0m, in \u001b[0;36mModelRunner.execute_model\u001b[0;34m(self, model_input, kv_caches, intermediate_tensors, num_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1823\u001b[0m     model_input\u001b[38;5;241m.\u001b[39masync_callback()\n\u001b[1;32m   1825\u001b[0m \u001b[38;5;66;03m# Sample the next token.\u001b[39;00m\n\u001b[0;32m-> 1826\u001b[0m output: SamplerOutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1827\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1828\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampling_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampling_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1829\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservability_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1831\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservability_config\u001b[38;5;241m.\u001b[39mcollect_model_forward_time\n\u001b[1;32m   1832\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1833\u001b[0m     model_forward_end\u001b[38;5;241m.\u001b[39msynchronize()\n",
      "File \u001b[0;32m~/miniconda3/envs/b3comp2/lib/python3.11/site-packages/vllm/model_executor/models/llama.py:556\u001b[0m, in \u001b[0;36mLlamaForCausalLM.sample\u001b[0;34m(self, logits, sampling_metadata)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample\u001b[39m(\u001b[38;5;28mself\u001b[39m, logits: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m    555\u001b[0m            sampling_metadata: SamplingMetadata) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[SamplerOutput]:\n\u001b[0;32m--> 556\u001b[0m     next_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m next_tokens\n",
      "File \u001b[0;32m~/miniconda3/envs/b3comp2/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/b3comp2/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/b3comp2/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py:287\u001b[0m, in \u001b[0;36mSampler.forward\u001b[0;34m(self, logits, sampling_metadata)\u001b[0m\n\u001b[1;32m    284\u001b[0m logprobs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog_softmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# Sample the next tokens.\u001b[39;00m\n\u001b[0;32m--> 287\u001b[0m maybe_deferred_sample_results, maybe_sampled_tokens_tensor \u001b[38;5;241m=\u001b[39m \u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampling_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampling_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_gpu_probs_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minclude_gpu_probs_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodify_greedy_probs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_modify_greedy_probs_inplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minclude_gpu_probs_tensor:\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;66;03m# Since we will defer sampler result Pythonization,\u001b[39;00m\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;66;03m# preserve GPU-side tensors in support of later\u001b[39;00m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;66;03m# deferred pythonization of logprobs\u001b[39;00m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m maybe_sampled_tokens_tensor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/b3comp2/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py:775\u001b[0m, in \u001b[0;36m_sample\u001b[0;34m(probs, logprobs, sampling_metadata, sampling_tensors, include_gpu_probs_tensor, modify_greedy_probs)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sample\u001b[39m(\n\u001b[1;32m    756\u001b[0m     probs: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m    757\u001b[0m     logprobs: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    761\u001b[0m     modify_greedy_probs: \u001b[38;5;28mbool\u001b[39m,\n\u001b[1;32m    762\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SampleReturnType:\n\u001b[1;32m    763\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;124;03m        probs: (num_query_tokens_in_batch, num_vocab)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;124;03m        sampled_token_ids_tensor: A tensor of sampled token ids.\u001b[39;00m\n\u001b[1;32m    774\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_sample_with_torch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m        \u001b[49m\u001b[43msampling_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m        \u001b[49m\u001b[43msampling_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude_gpu_probs_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_gpu_probs_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodify_greedy_probs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodify_greedy_probs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/b3comp2/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py:744\u001b[0m, in \u001b[0;36m_sample_with_torch\u001b[0;34m(probs, logprobs, sampling_metadata, sampling_tensors, include_gpu_probs_tensor, modify_greedy_probs)\u001b[0m\n\u001b[1;32m    733\u001b[0m maybe_deferred_args \u001b[38;5;241m=\u001b[39m SampleResultArgsType(\n\u001b[1;32m    734\u001b[0m     sampling_metadata\u001b[38;5;241m=\u001b[39msampling_metadata,\n\u001b[1;32m    735\u001b[0m     sample_metadata\u001b[38;5;241m=\u001b[39msample_metadata,\n\u001b[1;32m    736\u001b[0m     multinomial_samples\u001b[38;5;241m=\u001b[39mmultinomial_samples,\n\u001b[1;32m    737\u001b[0m     greedy_samples\u001b[38;5;241m=\u001b[39mgreedy_samples,\n\u001b[1;32m    738\u001b[0m     sample_results_dict\u001b[38;5;241m=\u001b[39msample_results_dict)\n\u001b[1;32m    740\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sampling_metadata\u001b[38;5;241m.\u001b[39mskip_sampler_cpu_output:\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;66;03m# GPU<->CPU sync happens here.\u001b[39;00m\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;66;03m# This also converts the sampler output to a Python object.\u001b[39;00m\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;66;03m# Return Pythonized sampler result & sampled token ids\u001b[39;00m\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_pythonized_sample_results\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaybe_deferred_args\u001b[49m\u001b[43m)\u001b[49m, sampled_token_ids_tensor\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;66;03m# Defer sampler result Pythonization; return deferred\u001b[39;00m\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;66;03m# Pythonization args & sampled token ids\u001b[39;00m\n\u001b[1;32m    749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    750\u001b[0m         maybe_deferred_args,\n\u001b[1;32m    751\u001b[0m         sampled_token_ids_tensor,\n\u001b[1;32m    752\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/b3comp2/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py:616\u001b[0m, in \u001b[0;36mget_pythonized_sample_results\u001b[0;34m(sample_result_args)\u001b[0m\n\u001b[1;32m    614\u001b[0m         sample_results \u001b[38;5;241m=\u001b[39m _greedy_sample(seq_groups, greedy_samples)\n\u001b[1;32m    615\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m sampling_type \u001b[38;5;129;01min\u001b[39;00m (SamplingType\u001b[38;5;241m.\u001b[39mRANDOM, SamplingType\u001b[38;5;241m.\u001b[39mRANDOM_SEED):\n\u001b[0;32m--> 616\u001b[0m         sample_results \u001b[38;5;241m=\u001b[39m \u001b[43m_random_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq_groups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mmultinomial_samples\u001b[49m\u001b[43m[\u001b[49m\u001b[43msampling_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    618\u001b[0m     sample_results_dict\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mzip\u001b[39m(seq_group_id, sample_results))\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    621\u001b[0m     sample_results_dict\u001b[38;5;241m.\u001b[39mget(i, ([], []))\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(sampling_metadata\u001b[38;5;241m.\u001b[39mseq_groups))\n\u001b[1;32m    623\u001b[0m ]\n",
      "File \u001b[0;32m~/miniconda3/envs/b3comp2/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py:485\u001b[0m, in \u001b[0;36m_random_sample\u001b[0;34m(selected_seq_groups, random_samples)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run random sampling on a given samples.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;124;03m    seq_group has do_sample=False, tuple contains ([], [])\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# Find the maximum n value of the prompt phase requests.\u001b[39;00m\n\u001b[0;32m--> 485\u001b[0m random_samples \u001b[38;5;241m=\u001b[39m \u001b[43mrandom_samples\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m sample_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    487\u001b[0m results: SampleResultType \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\" 温度パラメータの変更 \"\"\"\n",
    "\n",
    "for temp in ([0.1, 0.3, 0.5, 0.7, 0.9, 1.0]):\n",
    "    sampling_params = SamplingParams(\n",
    "        temperature=temp, top_p=0.9, max_tokens=512, stop=\"<|eot_id|>\"\n",
    "    )\n",
    "    print(f\"temperature: \", temp)\n",
    "    llm_score(sampling_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be2f5416",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processed prompts: 100%|██████████| 2/2 [00:01<00:00,  1.26it/s, est. speed input: 136.03 toks/s, output: 30.23 toks/s]\n",
      "  1%|          | 1/150 [00:01<03:58,  1.60s/it]\n",
      "\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, est. speed input: 130.12 toks/s, output: 9.64 toks/s]\n",
      "  1%|▏         | 2/150 [00:02<02:50,  1.15s/it]\n",
      "\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  5.32it/s, est. speed input: 672.43 toks/s, output: 10.84 toks/s]\n",
      "  2%|▏         | 3/150 [00:02<01:45,  1.40it/s]\n",
      "\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s, est. speed input: 663.42 toks/s, output: 12.52 toks/s]\n",
      "  3%|▎         | 4/150 [00:02<01:12,  2.01it/s]\n",
      "\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s, est. speed input: 154.21 toks/s, output: 11.53 toks/s]\n",
      "  3%|▎         | 5/150 [00:03<01:22,  1.75it/s]\n",
      "\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s, est. speed input: 138.06 toks/s, output: 9.94 toks/s]\n",
      "  4%|▍         | 6/150 [00:04<01:39,  1.45it/s]\n",
      "\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s, est. speed input: 126.23 toks/s, output: 9.90 toks/s]\n",
      "  5%|▍         | 7/150 [00:05<01:44,  1.37it/s]\n",
      "\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s, est. speed input: 669.22 toks/s, output: 10.71 toks/s]\n",
      "  5%|▌         | 8/150 [00:05<01:19,  1.78it/s]\n",
      "\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s, est. speed input: 756.54 toks/s, output: 11.91 toks/s]\n",
      "  6%|▌         | 9/150 [00:05<01:02,  2.27it/s]\n",
      "\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.99it/s, est. speed input: 224.23 toks/s, output: 12.01 toks/s]\n",
      "  7%|▋         | 10/150 [00:06<01:04,  2.17it/s]\n",
      "\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, est. speed input: 507.16 toks/s, output: 10.24 toks/s]\n",
      "  7%|▋         | 11/150 [00:06<00:53,  2.62it/s]\n",
      "\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:04<00:00,  4.94s/it, est. speed input: 22.91 toks/s, output: 8.72 toks/s]\n",
      "  8%|▊         | 12/150 [00:11<04:04,  1.77s/it]\n",
      "\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  5.42it/s, est. speed input: 565.99 toks/s, output: 10.99 toks/s]\n",
      "  9%|▊         | 13/150 [00:11<02:56,  1.29s/it]\n",
      "\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.91it/s, est. speed input: 202.05 toks/s, output: 11.55 toks/s]\n",
      "  9%|▉         | 14/150 [00:11<02:24,  1.06s/it]\n",
      "\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s, est. speed input: 154.73 toks/s, output: 10.09 toks/s]\n",
      " 10%|█         | 15/150 [00:12<02:04,  1.08it/s]\n",
      "\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.11s/it, est. speed input: 111.92 toks/s, output: 9.03 toks/s]\n",
      " 11%|█         | 16/150 [00:13<02:11,  1.02it/s]\n",
      " 11%|█         | 16/150 [00:19<02:44,  1.23s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m messages \u001b[38;5;241m=\u001b[39m create_prompt(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m問題\u001b[39m\u001b[38;5;124m\"\u001b[39m], row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m選択肢A\u001b[39m\u001b[38;5;124m\"\u001b[39m], row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m選択肢B\u001b[39m\u001b[38;5;124m\"\u001b[39m], row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m選択肢C\u001b[39m\u001b[38;5;124m\"\u001b[39m], row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m選択肢D\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     39\u001b[0m prompt \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(messages, tokenize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 41\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m answer \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39moutputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;241m.\u001b[39mstartswith(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m正解\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mupper()):\n",
      "File \u001b[0;32m~/miniconda3/envs/b3comp2/lib/python3.11/site-packages/vllm/utils.py:1134\u001b[0m, in \u001b[0;36mdeprecate_kwargs.<locals>.wrapper.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m             msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00madditional_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1129\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1130\u001b[0m             \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m(msg),\n\u001b[1;32m   1131\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# The inner function takes up one level\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m         )\n\u001b[0;32m-> 1134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/b3comp2/lib/python3.11/site-packages/vllm/entrypoints/llm.py:470\u001b[0m, in \u001b[0;36mLLM.generate\u001b[0;34m(self, prompts, sampling_params, prompt_token_ids, use_tqdm, lora_request, prompt_adapter_request, guided_options_request, priority)\u001b[0m\n\u001b[1;32m    460\u001b[0m     sampling_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_default_sampling_params()\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_and_add_requests(\n\u001b[1;32m    463\u001b[0m     prompts\u001b[38;5;241m=\u001b[39mparsed_prompts,\n\u001b[1;32m    464\u001b[0m     params\u001b[38;5;241m=\u001b[39msampling_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    467\u001b[0m     guided_options\u001b[38;5;241m=\u001b[39mguided_options_request,\n\u001b[1;32m    468\u001b[0m     priority\u001b[38;5;241m=\u001b[39mpriority)\n\u001b[0;32m--> 470\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_tqdm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_class\u001b[38;5;241m.\u001b[39mvalidate_outputs(outputs, RequestOutput)\n",
      "File \u001b[0;32m~/miniconda3/envs/b3comp2/lib/python3.11/site-packages/vllm/entrypoints/llm.py:1409\u001b[0m, in \u001b[0;36mLLM._run_engine\u001b[0;34m(self, use_tqdm)\u001b[0m\n\u001b[1;32m   1407\u001b[0m total_out_toks \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1408\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_engine\u001b[38;5;241m.\u001b[39mhas_unfinished_requests():\n\u001b[0;32m-> 1409\u001b[0m     step_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m step_outputs:\n\u001b[1;32m   1411\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output\u001b[38;5;241m.\u001b[39mfinished:\n",
      "File \u001b[0;32m~/miniconda3/envs/b3comp2/lib/python3.11/site-packages/vllm/engine/llm_engine.py:1431\u001b[0m, in \u001b[0;36mLLMEngine.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     execute_model_req\u001b[38;5;241m.\u001b[39masync_callback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_callbacks[\n\u001b[1;32m   1428\u001b[0m         virtual_engine]\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1431\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecute_model_req\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecute_model_req\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1433\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_skip_scheduling_next_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1434\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InputProcessingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1435\u001b[0m     \u001b[38;5;66;03m# The input for this request cannot be processed, so we must\u001b[39;00m\n\u001b[1;32m   1436\u001b[0m     \u001b[38;5;66;03m# abort it. If there are remaining requests in the batch that\u001b[39;00m\n\u001b[1;32m   1437\u001b[0m     \u001b[38;5;66;03m# have been scheduled, they will be retried on the next step.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/b3comp2/lib/python3.11/site-packages/vllm/executor/executor_base.py:140\u001b[0m, in \u001b[0;36mExecutorBase.execute_model\u001b[0;34m(self, execute_model_req)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute_model\u001b[39m(\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m, execute_model_req: ExecuteModelRequest\n\u001b[1;32m    139\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[List[Union[SamplerOutput, PoolerOutput]]]:\n\u001b[0;32m--> 140\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollective_rpc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexecute_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexecute_model_req\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/b3comp2/lib/python3.11/site-packages/vllm/executor/uniproc_executor.py:56\u001b[0m, in \u001b[0;36mUniProcExecutor.collective_rpc\u001b[0;34m(self, method, timeout, args, kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 56\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mrun_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdriver_worker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [answer]\n",
      "File \u001b[0;32m~/miniconda3/envs/b3comp2/lib/python3.11/site-packages/vllm/utils.py:2378\u001b[0m, in \u001b[0;36mrun_method\u001b[0;34m(obj, method, args, kwargs)\u001b[0m\n\u001b[1;32m   2376\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2377\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(method, obj)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 2378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/b3comp2/lib/python3.11/site-packages/vllm/worker/worker_base.py:420\u001b[0m, in \u001b[0;36mLocalOrDistributedWorkerBase.execute_model\u001b[0;34m(self, execute_model_req)\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservability_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    416\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservability_config\u001b[38;5;241m.\u001b[39mcollect_model_execute_time):\n\u001b[1;32m    417\u001b[0m         orig_model_execute_time \u001b[38;5;241m=\u001b[39m intermediate_tensors\u001b[38;5;241m.\u001b[39mtensors\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    418\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_execute_time\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m--> 420\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkv_caches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mworker_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvirtual_engine\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintermediate_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mintermediate_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m model_execute_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m get_pp_group()\u001b[38;5;241m.\u001b[39mis_last_rank:\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;66;03m# output is IntermediateTensors\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/b3comp2/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/b3comp2/lib/python3.11/site-packages/vllm/worker/model_runner.py:1826\u001b[0m, in \u001b[0;36mModelRunner.execute_model\u001b[0;34m(self, model_input, kv_caches, intermediate_tensors, num_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1823\u001b[0m     model_input\u001b[38;5;241m.\u001b[39masync_callback()\n\u001b[1;32m   1825\u001b[0m \u001b[38;5;66;03m# Sample the next token.\u001b[39;00m\n\u001b[0;32m-> 1826\u001b[0m output: SamplerOutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1827\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1828\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampling_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampling_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1829\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservability_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1831\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservability_config\u001b[38;5;241m.\u001b[39mcollect_model_forward_time\n\u001b[1;32m   1832\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1833\u001b[0m     model_forward_end\u001b[38;5;241m.\u001b[39msynchronize()\n",
      "File \u001b[0;32m~/miniconda3/envs/b3comp2/lib/python3.11/site-packages/vllm/model_executor/models/llama.py:556\u001b[0m, in \u001b[0;36mLlamaForCausalLM.sample\u001b[0;34m(self, logits, sampling_metadata)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample\u001b[39m(\u001b[38;5;28mself\u001b[39m, logits: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m    555\u001b[0m            sampling_metadata: SamplingMetadata) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[SamplerOutput]:\n\u001b[0;32m--> 556\u001b[0m     next_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m next_tokens\n",
      "File \u001b[0;32m~/miniconda3/envs/b3comp2/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/b3comp2/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/b3comp2/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py:287\u001b[0m, in \u001b[0;36mSampler.forward\u001b[0;34m(self, logits, sampling_metadata)\u001b[0m\n\u001b[1;32m    284\u001b[0m logprobs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog_softmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# Sample the next tokens.\u001b[39;00m\n\u001b[0;32m--> 287\u001b[0m maybe_deferred_sample_results, maybe_sampled_tokens_tensor \u001b[38;5;241m=\u001b[39m \u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampling_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampling_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_gpu_probs_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minclude_gpu_probs_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodify_greedy_probs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_modify_greedy_probs_inplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minclude_gpu_probs_tensor:\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;66;03m# Since we will defer sampler result Pythonization,\u001b[39;00m\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;66;03m# preserve GPU-side tensors in support of later\u001b[39;00m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;66;03m# deferred pythonization of logprobs\u001b[39;00m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m maybe_sampled_tokens_tensor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/b3comp2/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py:775\u001b[0m, in \u001b[0;36m_sample\u001b[0;34m(probs, logprobs, sampling_metadata, sampling_tensors, include_gpu_probs_tensor, modify_greedy_probs)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sample\u001b[39m(\n\u001b[1;32m    756\u001b[0m     probs: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m    757\u001b[0m     logprobs: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    761\u001b[0m     modify_greedy_probs: \u001b[38;5;28mbool\u001b[39m,\n\u001b[1;32m    762\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SampleReturnType:\n\u001b[1;32m    763\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;124;03m        probs: (num_query_tokens_in_batch, num_vocab)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;124;03m        sampled_token_ids_tensor: A tensor of sampled token ids.\u001b[39;00m\n\u001b[1;32m    774\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_sample_with_torch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m        \u001b[49m\u001b[43msampling_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m        \u001b[49m\u001b[43msampling_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude_gpu_probs_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_gpu_probs_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodify_greedy_probs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodify_greedy_probs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/b3comp2/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py:744\u001b[0m, in \u001b[0;36m_sample_with_torch\u001b[0;34m(probs, logprobs, sampling_metadata, sampling_tensors, include_gpu_probs_tensor, modify_greedy_probs)\u001b[0m\n\u001b[1;32m    733\u001b[0m maybe_deferred_args \u001b[38;5;241m=\u001b[39m SampleResultArgsType(\n\u001b[1;32m    734\u001b[0m     sampling_metadata\u001b[38;5;241m=\u001b[39msampling_metadata,\n\u001b[1;32m    735\u001b[0m     sample_metadata\u001b[38;5;241m=\u001b[39msample_metadata,\n\u001b[1;32m    736\u001b[0m     multinomial_samples\u001b[38;5;241m=\u001b[39mmultinomial_samples,\n\u001b[1;32m    737\u001b[0m     greedy_samples\u001b[38;5;241m=\u001b[39mgreedy_samples,\n\u001b[1;32m    738\u001b[0m     sample_results_dict\u001b[38;5;241m=\u001b[39msample_results_dict)\n\u001b[1;32m    740\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sampling_metadata\u001b[38;5;241m.\u001b[39mskip_sampler_cpu_output:\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;66;03m# GPU<->CPU sync happens here.\u001b[39;00m\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;66;03m# This also converts the sampler output to a Python object.\u001b[39;00m\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;66;03m# Return Pythonized sampler result & sampled token ids\u001b[39;00m\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_pythonized_sample_results\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaybe_deferred_args\u001b[49m\u001b[43m)\u001b[49m, sampled_token_ids_tensor\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;66;03m# Defer sampler result Pythonization; return deferred\u001b[39;00m\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;66;03m# Pythonization args & sampled token ids\u001b[39;00m\n\u001b[1;32m    749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    750\u001b[0m         maybe_deferred_args,\n\u001b[1;32m    751\u001b[0m         sampled_token_ids_tensor,\n\u001b[1;32m    752\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/b3comp2/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py:616\u001b[0m, in \u001b[0;36mget_pythonized_sample_results\u001b[0;34m(sample_result_args)\u001b[0m\n\u001b[1;32m    614\u001b[0m         sample_results \u001b[38;5;241m=\u001b[39m _greedy_sample(seq_groups, greedy_samples)\n\u001b[1;32m    615\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m sampling_type \u001b[38;5;129;01min\u001b[39;00m (SamplingType\u001b[38;5;241m.\u001b[39mRANDOM, SamplingType\u001b[38;5;241m.\u001b[39mRANDOM_SEED):\n\u001b[0;32m--> 616\u001b[0m         sample_results \u001b[38;5;241m=\u001b[39m \u001b[43m_random_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq_groups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mmultinomial_samples\u001b[49m\u001b[43m[\u001b[49m\u001b[43msampling_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    618\u001b[0m     sample_results_dict\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mzip\u001b[39m(seq_group_id, sample_results))\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    621\u001b[0m     sample_results_dict\u001b[38;5;241m.\u001b[39mget(i, ([], []))\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(sampling_metadata\u001b[38;5;241m.\u001b[39mseq_groups))\n\u001b[1;32m    623\u001b[0m ]\n",
      "File \u001b[0;32m~/miniconda3/envs/b3comp2/lib/python3.11/site-packages/vllm/model_executor/layers/sampler.py:485\u001b[0m, in \u001b[0;36m_random_sample\u001b[0;34m(selected_seq_groups, random_samples)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run random sampling on a given samples.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;124;03m    seq_group has do_sample=False, tuple contains ([], [])\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# Find the maximum n value of the prompt phase requests.\u001b[39;00m\n\u001b[0;32m--> 485\u001b[0m random_samples \u001b[38;5;241m=\u001b[39m \u001b[43mrandom_samples\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m sample_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    487\u001b[0m results: SampleResultType \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\" プロンプト \"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from vllm import LLM, SamplingParams\n",
    "from tqdm import tqdm\n",
    "\n",
    "# モデルとトークナイザの準備\n",
    "# model_name = \"tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# llm = LLM(\n",
    "#     model=model_name,\n",
    "#     tensor_parallel_size=1,\n",
    "#     dtype=\"float16\",\n",
    "# )\n",
    "\n",
    "sampling_params = SamplingParams(\n",
    "    temperature=0.6, top_p=0.9, max_tokens=512, stop=\"<|eot_id|>\"\n",
    ")\n",
    "\n",
    "df = pd.read_csv(\"JMMLU/JMMLU/japanese_history.csv\", header=None)\n",
    "df.columns = [\"問題\", \"選択肢A\", \"選択肢B\", \"選択肢C\", \"選択肢D\", \"正解\"]\n",
    "\n",
    "def create_prompt(question, a, b, c, d):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": \"あなたは誠実で優秀な日本人のアシスタントです。\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"{question}\\nA. {a}\\nB. {b}\\nC. {c}\\nD. {d}\\n正しい選択肢を一つだけアルファベットで答えてください。\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "correct = 0\n",
    "total = len(df)\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=total):\n",
    "    messages = create_prompt(row[\"問題\"], row[\"選択肢A\"], row[\"選択肢B\"], row[\"選択肢C\"], row[\"選択肢D\"])\n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "    output = llm.generate(prompt, sampling_params)\n",
    "    answer = output[0].outputs[0].text.strip()\n",
    "\n",
    "    if answer.upper().startswith(row[\"正解\"].strip().upper()):\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / total * 100\n",
    "print(f\"正解数: {correct} / {total} = {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf416fce",
   "metadata": {},
   "source": [
    "### 44. 対話\n",
    "\n",
    "以下の問いかけに対する応答を生成せよ。\n",
    "\n",
    "つばめちゃんは渋谷駅から東急東横線に乗り、自由が丘駅で乗り換えました。東急大井町線の大井町方面の電車に乗り換えたとき、各駅停車に乗車すべきところ、間違えて急行に乗車してしまったことに気付きました。自由が丘の次の急行停車駅で降車し、反対方向の電車で一駅戻った駅がつばめちゃんの目的地でした。目的地の駅の名前を答えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eff45311",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:05<00:00,  5.10s/it, est. speed input: 32.76 toks/s, output: 10.01 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "つばめちゃんの目的地は **緑が丘駅** です。 \n",
      "\n",
      "\n",
      "東急大井町線の急行は自由が丘駅から次の停車駅は **緑が丘駅** です。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "model_name = \"tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3\"\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# llm = LLM(\n",
    "#     model=model_name,\n",
    "#     tensor_parallel_size=1,\n",
    "#     dtype=\"float16\",\n",
    "# )\n",
    "\n",
    "sampling_params = SamplingParams(\n",
    "    temperature=0.6, top_p=0.9, max_tokens=512, stop=\"<|eot_id|>\"\n",
    ")\n",
    "\n",
    "\n",
    "message = [\n",
    "    {\"role\": \"system\", \"content\": \"あなたは誠実で優秀な日本人のアシスタントです。次の質問に回答してください\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"つばめちゃんは渋谷駅から東急東横線に乗り、自由が丘駅で乗り換えました。東急大井町線の大井町方面の電車に乗り換えたとき、各駅停車に乗車すべきところ、間違えて急行に乗車してしまったことに気付きました。自由が丘の次の急行停車駅で降車し、反対方向の電車で一駅戻った駅がつばめちゃんの目的地でした。目的地の駅の名前を答えてください。\"\n",
    "    },\n",
    "]\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    message, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "output = llm.generate(prompt, sampling_params)\n",
    "\n",
    "print(output[0].outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42b578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "つばめちゃんの目的地は **緑が丘駅** です。 \n",
    "\n",
    "\n",
    "東急大井町線の急行は自由が丘駅から次の停車駅は **緑が丘駅** です。\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "b3comp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
